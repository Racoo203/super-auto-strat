{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "5a52990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "4e7d0d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/pets.html', 'r', encoding='utf-8') as file:\n",
    "    soup = BeautifulSoup(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5505b01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = soup.find_all('article', class_='tabber__panel')\n",
    "tier_info = info[:-1]\n",
    "token_info = info[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "17378926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pet_data(tier_info):\n",
    "    tier_data = []\n",
    "    for tier in tier_info:\n",
    "        tier_name = tier.find('h3').get_text(strip=True)\n",
    "        table = tier.find('table', class_='wikitable')\n",
    "        if not table:\n",
    "            continue\n",
    "\n",
    "        for row in table.find_all('tr'):\n",
    "            cells = row.find_all('td')\n",
    "            if not cells:\n",
    "                continue\n",
    "\n",
    "            if cells[0].has_attr('rowspan'):\n",
    "                rowspan = int(cells[0]['rowspan'])\n",
    "                name = cells[0].find('a')['title']\n",
    "                attack = cells[1].get_text(strip=True)\n",
    "                health = cells[2].get_text(strip=True)\n",
    "                pack_ref = cells[-1].find_all('a')\n",
    "                packs = [ref.get('title', '').strip() for ref in pack_ref]\n",
    "\n",
    "                ability_rows = [row] + [row.find_next_sibling('tr', recursive=False) for _ in range(rowspan - 1)]\n",
    "                for idx, ability_row in enumerate(ability_rows):\n",
    "                    ability_cells = ability_row.find_all('td')\n",
    "                    if idx == 0:\n",
    "                        Level = ability_cells[3].text.strip()\n",
    "                        ability_desc = ability_cells[4].text.strip()\n",
    "                    else:\n",
    "                        Level = ability_cells[0].text.strip()\n",
    "                        ability_desc = ability_cells[1].text.strip()\n",
    "\n",
    "                    tier_data.append({\n",
    "                        'Name': name,\n",
    "                        'Attack': attack,\n",
    "                        'Health': health,\n",
    "                        'Level': Level,\n",
    "                        'Ability': ability_desc,\n",
    "                        'Packs': packs,\n",
    "                        'Tier': tier_name\n",
    "                    })\n",
    "    pets_df = pd.DataFrame(tier_data)\n",
    "\n",
    "    return pets_df\n",
    "\n",
    "def extract_token_data(token_info):\n",
    "    table = token_info.find('table', class_='wikitable')\n",
    "    df = pd.read_html(str(table), header=[0, 1])[0]\n",
    "\n",
    "    # Expand rows where 'Level 2 & 3' appears in the ability table\n",
    "    # Expand rows where 'Level 2 & 3' appears in the ability table\n",
    "    if any(df.iloc[:, 0].astype(str).str.contains('Level 2 & 3')):\n",
    "        rows_to_add = []\n",
    "        for idx, row in df.iterrows():\n",
    "            if str(row[0]).strip() == 'Level 2 & 3':\n",
    "                for lvl in ['Level 2', 'Level 3']:\n",
    "                    new_row = row.copy()\n",
    "                    new_row[0] = lvl\n",
    "                    rows_to_add.append((idx, new_row))\n",
    "        # Insert new rows after the original and drop the 'Level 2 & 3' row\n",
    "        for offset, (idx, new_row) in enumerate(rows_to_add):\n",
    "            df = pd.concat([\n",
    "                df.iloc[:idx + 1 + offset],\n",
    "                pd.DataFrame([new_row], columns=df.columns),\n",
    "                df.iloc[idx + 1 + offset:]\n",
    "            ]).reset_index(drop=True)\n",
    "        df = df[df.iloc[:, 0] != 'Level 2 & 3'].reset_index(drop=True)\n",
    "    \n",
    "    # Flatten column names\n",
    "    df.columns = ['_'.join(col).strip().replace(' ', '_') for col in df.columns.values]\n",
    "\n",
    "    # Separate rows into token rows and ability description rows\n",
    "    token_rows = df[~df['Name_Name'].str.match(r'^Level \\d$', na=False)].copy()\n",
    "    ability_rows = df[df['Name_Name'].str.match(r'^Level \\d$', na=False)].copy()\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    token_rows = token_rows.rename(columns={\n",
    "        'Name_Name': 'Name',\n",
    "        'Unnamed:_1_level_0_Level_1': 'Level_1',\n",
    "        'Unnamed:_2_level_0_Level_2': 'Level_2',\n",
    "        'Unnamed:_3_level_0_Level_3': 'Level_3',\n",
    "        'Ability_Ability': 'Ability',\n",
    "        'Summoned_From_Summoned_From': 'Summoned_From',\n",
    "        'Additional_Notes_Additional_Notes': 'Notes'\n",
    "    })\n",
    "\n",
    "    # Forward-fill the Name in ability description rows to associate with the last token\n",
    "    ability_rows['Ability_Level'] = ability_rows['Name_Name'].str.extract(r'Level (\\d)').astype(int)\n",
    "    ability_rows['Ability_Description'] = ability_rows['Unnamed:_1_level_0_Level_1']\n",
    "    ability_rows['Name'] = pd.NA\n",
    "\n",
    "    last_name = None\n",
    "    names = []\n",
    "    for idx, row in ability_rows.iterrows():\n",
    "        if idx > 0:\n",
    "            # Search backward for the last valid token name before this group\n",
    "            for rev_idx in range(idx - 1, -1, -1):\n",
    "                if rev_idx in token_rows.index:\n",
    "                    last_name = token_rows.loc[rev_idx, 'Name']\n",
    "                    break\n",
    "        names.append(last_name)\n",
    "    ability_rows['Name'] = names\n",
    "\n",
    "    ability_rows = ability_rows[['Name', 'Ability_Level', 'Ability_Description']].dropna()\n",
    "\n",
    "    # Melt the token stats into long format\n",
    "    token_long = pd.melt(\n",
    "        token_rows,\n",
    "        id_vars=['Name', 'Ability', 'Summoned_From', 'Notes'],\n",
    "        value_vars=['Level_1', 'Level_2', 'Level_3'],\n",
    "        var_name='Level',\n",
    "        value_name='Stats'\n",
    "    )\n",
    "\n",
    "    token_long['Ability_Level'] = token_long['Level'].str.extract(r'Level_(\\d)').astype(int)\n",
    "\n",
    "    # Split Stats into Attack and Health\n",
    "    stat_split = token_long['Stats'].str.extract(r'(?P<Attack>[\\dX/*\\(\\)]+)[/](?P<Health>[\\dX/*\\(\\)]+)')\n",
    "    token_long = pd.concat([token_long, stat_split], axis=1)\n",
    "\n",
    "    # Merge ability descriptions\n",
    "    final_df = pd.merge(token_long, ability_rows, how='left', on=['Name', 'Ability_Level'])\n",
    "\n",
    "    # Select and reorder columns\n",
    "    final_df = final_df[['Name', 'Attack', 'Health', 'Ability_Level', 'Ability_Description', 'Summoned_From', 'Notes']]\n",
    "    final_df.sort_values(by=['Name', 'Ability_Level'], inplace=True)\n",
    "    final_df.reset_index(drop=True, inplace=True)\n",
    "    final_df.rename(columns={\n",
    "        'Ability_Level': 'Level',\n",
    "        'Ability_Description': 'Ability',\n",
    "        'Summoned_From': 'Summoned From',\n",
    "    }, inplace=True)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "cd272d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pets data to CSV.\n",
      "Saved tokens data to CSV.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rcorr\\AppData\\Local\\Temp\\ipykernel_19392\\1633096354.py:47: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table), header=[0, 1])[0]\n",
      "C:\\Users\\rcorr\\AppData\\Local\\Temp\\ipykernel_19392\\1633096354.py:54: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if str(row[0]).strip() == 'Level 2 & 3':\n",
      "C:\\Users\\rcorr\\AppData\\Local\\Temp\\ipykernel_19392\\1633096354.py:57: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  new_row[0] = lvl\n"
     ]
    }
   ],
   "source": [
    "pets_df = extract_pet_data(tier_info)\n",
    "tokens_df = extract_token_data(token_info)\n",
    "\n",
    "df_ids = ['pets', 'tokens']\n",
    "\n",
    "\n",
    "for df_id, df in zip(df_ids, [pets_df, tokens_df]):\n",
    "    df.to_csv(f'../data/{df_id}.csv', index=False)\n",
    "    print(f\"Saved {df_id} data to CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b848f51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "super-auto-strat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
